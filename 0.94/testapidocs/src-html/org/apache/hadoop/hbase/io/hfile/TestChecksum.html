<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en">
<head>
<title>Source code</title>
<link rel="stylesheet" type="text/css" href="../../../../../../../stylesheet.css" title="Style">
</head>
<body>
<div class="sourceContainer">
<pre><span class="sourceLineNo">001</span>/*<a name="line.1"></a>
<span class="sourceLineNo">002</span> * Copyright The Apache Software Foundation<a name="line.2"></a>
<span class="sourceLineNo">003</span> *<a name="line.3"></a>
<span class="sourceLineNo">004</span> * Licensed to the Apache Software Foundation (ASF) under one<a name="line.4"></a>
<span class="sourceLineNo">005</span> * or more contributor license agreements.  See the NOTICE file<a name="line.5"></a>
<span class="sourceLineNo">006</span> * distributed with this work for additional information<a name="line.6"></a>
<span class="sourceLineNo">007</span> * regarding copyright ownership.  The ASF licenses this file<a name="line.7"></a>
<span class="sourceLineNo">008</span> * to you under the Apache License, Version 2.0 (the<a name="line.8"></a>
<span class="sourceLineNo">009</span> * "License"); you may not use this file except in compliance<a name="line.9"></a>
<span class="sourceLineNo">010</span> * with the License.  You may obtain a copy of the License at<a name="line.10"></a>
<span class="sourceLineNo">011</span> *<a name="line.11"></a>
<span class="sourceLineNo">012</span> *     http://www.apache.org/licenses/LICENSE-2.0<a name="line.12"></a>
<span class="sourceLineNo">013</span> *<a name="line.13"></a>
<span class="sourceLineNo">014</span> * Unless required by applicable law or agreed to in writing, software<a name="line.14"></a>
<span class="sourceLineNo">015</span> * distributed under the License is distributed on an "AS IS" BASIS,<a name="line.15"></a>
<span class="sourceLineNo">016</span> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<a name="line.16"></a>
<span class="sourceLineNo">017</span> * See the License for the specific language governing permissions and<a name="line.17"></a>
<span class="sourceLineNo">018</span> * limitations under the License.<a name="line.18"></a>
<span class="sourceLineNo">019</span> */<a name="line.19"></a>
<span class="sourceLineNo">020</span>package org.apache.hadoop.hbase.io.hfile;<a name="line.20"></a>
<span class="sourceLineNo">021</span><a name="line.21"></a>
<span class="sourceLineNo">022</span>import static org.junit.Assert.*;<a name="line.22"></a>
<span class="sourceLineNo">023</span><a name="line.23"></a>
<span class="sourceLineNo">024</span>import java.io.ByteArrayInputStream;<a name="line.24"></a>
<span class="sourceLineNo">025</span>import java.io.DataOutputStream;<a name="line.25"></a>
<span class="sourceLineNo">026</span>import java.io.DataInputStream;<a name="line.26"></a>
<span class="sourceLineNo">027</span>import java.io.IOException;<a name="line.27"></a>
<span class="sourceLineNo">028</span>import java.nio.ByteBuffer;<a name="line.28"></a>
<span class="sourceLineNo">029</span><a name="line.29"></a>
<span class="sourceLineNo">030</span>import org.apache.commons.logging.Log;<a name="line.30"></a>
<span class="sourceLineNo">031</span>import org.apache.commons.logging.LogFactory;<a name="line.31"></a>
<span class="sourceLineNo">032</span>import org.apache.hadoop.fs.FSDataInputStream;<a name="line.32"></a>
<span class="sourceLineNo">033</span>import org.apache.hadoop.fs.FSDataOutputStream;<a name="line.33"></a>
<span class="sourceLineNo">034</span>import org.apache.hadoop.fs.FileSystem;<a name="line.34"></a>
<span class="sourceLineNo">035</span>import org.apache.hadoop.fs.Path;<a name="line.35"></a>
<span class="sourceLineNo">036</span>import org.apache.hadoop.hbase.HBaseTestingUtility;<a name="line.36"></a>
<span class="sourceLineNo">037</span>import org.apache.hadoop.hbase.MediumTests;<a name="line.37"></a>
<span class="sourceLineNo">038</span>import org.apache.hadoop.hbase.fs.HFileSystem;<a name="line.38"></a>
<span class="sourceLineNo">039</span>import org.apache.hadoop.hbase.io.hfile.Compression.Algorithm;<a name="line.39"></a>
<span class="sourceLineNo">040</span>import org.apache.hadoop.hbase.util.ChecksumType;<a name="line.40"></a>
<span class="sourceLineNo">041</span><a name="line.41"></a>
<span class="sourceLineNo">042</span>import static org.apache.hadoop.hbase.io.hfile.Compression.Algorithm.*;<a name="line.42"></a>
<span class="sourceLineNo">043</span>import org.junit.Before;<a name="line.43"></a>
<span class="sourceLineNo">044</span>import org.junit.Test;<a name="line.44"></a>
<span class="sourceLineNo">045</span>import org.junit.experimental.categories.Category;<a name="line.45"></a>
<span class="sourceLineNo">046</span><a name="line.46"></a>
<span class="sourceLineNo">047</span>@Category(MediumTests.class)<a name="line.47"></a>
<span class="sourceLineNo">048</span>public class TestChecksum {<a name="line.48"></a>
<span class="sourceLineNo">049</span>  // change this value to activate more logs<a name="line.49"></a>
<span class="sourceLineNo">050</span>  private static final boolean detailedLogging = true;<a name="line.50"></a>
<span class="sourceLineNo">051</span>  private static final boolean[] BOOLEAN_VALUES = new boolean[] { false, true };<a name="line.51"></a>
<span class="sourceLineNo">052</span><a name="line.52"></a>
<span class="sourceLineNo">053</span>  private static final Log LOG = LogFactory.getLog(TestHFileBlock.class);<a name="line.53"></a>
<span class="sourceLineNo">054</span><a name="line.54"></a>
<span class="sourceLineNo">055</span>  static final Compression.Algorithm[] COMPRESSION_ALGORITHMS = {<a name="line.55"></a>
<span class="sourceLineNo">056</span>      NONE, GZ };<a name="line.56"></a>
<span class="sourceLineNo">057</span><a name="line.57"></a>
<span class="sourceLineNo">058</span>  static final int[] BYTES_PER_CHECKSUM = {<a name="line.58"></a>
<span class="sourceLineNo">059</span>      50, 500, 688, 16*1024, (16*1024+980), 64 * 1024};<a name="line.59"></a>
<span class="sourceLineNo">060</span><a name="line.60"></a>
<span class="sourceLineNo">061</span>  private static final HBaseTestingUtility TEST_UTIL =<a name="line.61"></a>
<span class="sourceLineNo">062</span>    new HBaseTestingUtility();<a name="line.62"></a>
<span class="sourceLineNo">063</span>  private FileSystem fs;<a name="line.63"></a>
<span class="sourceLineNo">064</span>  private HFileSystem hfs;<a name="line.64"></a>
<span class="sourceLineNo">065</span><a name="line.65"></a>
<span class="sourceLineNo">066</span>  @Before<a name="line.66"></a>
<span class="sourceLineNo">067</span>  public void setUp() throws Exception {<a name="line.67"></a>
<span class="sourceLineNo">068</span>    fs = HFileSystem.get(TEST_UTIL.getConfiguration());<a name="line.68"></a>
<span class="sourceLineNo">069</span>    hfs = (HFileSystem)fs;<a name="line.69"></a>
<span class="sourceLineNo">070</span>  }<a name="line.70"></a>
<span class="sourceLineNo">071</span><a name="line.71"></a>
<span class="sourceLineNo">072</span>  /**<a name="line.72"></a>
<span class="sourceLineNo">073</span>   * Introduce checksum failures and check that we can still read<a name="line.73"></a>
<span class="sourceLineNo">074</span>   * the data<a name="line.74"></a>
<span class="sourceLineNo">075</span>   */<a name="line.75"></a>
<span class="sourceLineNo">076</span>  @Test<a name="line.76"></a>
<span class="sourceLineNo">077</span>  public void testChecksumCorruption() throws IOException {<a name="line.77"></a>
<span class="sourceLineNo">078</span>    for (Compression.Algorithm algo : COMPRESSION_ALGORITHMS) {<a name="line.78"></a>
<span class="sourceLineNo">079</span>      for (boolean pread : new boolean[] { false, true }) {<a name="line.79"></a>
<span class="sourceLineNo">080</span>        LOG.info("testChecksumCorruption: Compression algorithm: " + algo +<a name="line.80"></a>
<span class="sourceLineNo">081</span>                   ", pread=" + pread);<a name="line.81"></a>
<span class="sourceLineNo">082</span>        Path path = new Path(TEST_UTIL.getDataTestDir(), "blocks_v2_"<a name="line.82"></a>
<span class="sourceLineNo">083</span>            + algo);<a name="line.83"></a>
<span class="sourceLineNo">084</span>        FSDataOutputStream os = fs.create(path);<a name="line.84"></a>
<span class="sourceLineNo">085</span>        HFileBlock.Writer hbw = new HFileBlock.Writer(algo, null,<a name="line.85"></a>
<span class="sourceLineNo">086</span>            true, 1, HFile.DEFAULT_CHECKSUM_TYPE,<a name="line.86"></a>
<span class="sourceLineNo">087</span>            HFile.DEFAULT_BYTES_PER_CHECKSUM);<a name="line.87"></a>
<span class="sourceLineNo">088</span>        long totalSize = 0;<a name="line.88"></a>
<span class="sourceLineNo">089</span>        for (int blockId = 0; blockId &lt; 2; ++blockId) {<a name="line.89"></a>
<span class="sourceLineNo">090</span>          DataOutputStream dos = hbw.startWriting(BlockType.DATA);<a name="line.90"></a>
<span class="sourceLineNo">091</span>          for (int i = 0; i &lt; 1234; ++i)<a name="line.91"></a>
<span class="sourceLineNo">092</span>            dos.writeInt(i);<a name="line.92"></a>
<span class="sourceLineNo">093</span>          hbw.writeHeaderAndData(os);<a name="line.93"></a>
<span class="sourceLineNo">094</span>          totalSize += hbw.getOnDiskSizeWithHeader();<a name="line.94"></a>
<span class="sourceLineNo">095</span>        }<a name="line.95"></a>
<span class="sourceLineNo">096</span>        os.close();<a name="line.96"></a>
<span class="sourceLineNo">097</span><a name="line.97"></a>
<span class="sourceLineNo">098</span>        // Use hbase checksums. <a name="line.98"></a>
<span class="sourceLineNo">099</span>        assertEquals(true, hfs.useHBaseChecksum());<a name="line.99"></a>
<span class="sourceLineNo">100</span><a name="line.100"></a>
<span class="sourceLineNo">101</span>        // Do a read that purposely introduces checksum verification failures.<a name="line.101"></a>
<span class="sourceLineNo">102</span>        FSDataInputStream is = fs.open(path);<a name="line.102"></a>
<span class="sourceLineNo">103</span>        HFileBlock.FSReader hbr = new FSReaderV2Test(is, algo,<a name="line.103"></a>
<span class="sourceLineNo">104</span>            totalSize, HFile.MAX_FORMAT_VERSION, fs, path);<a name="line.104"></a>
<span class="sourceLineNo">105</span>        HFileBlock b = hbr.readBlockData(0, -1, -1, pread);<a name="line.105"></a>
<span class="sourceLineNo">106</span>        b.sanityCheck();<a name="line.106"></a>
<span class="sourceLineNo">107</span>        assertEquals(4936, b.getUncompressedSizeWithoutHeader());<a name="line.107"></a>
<span class="sourceLineNo">108</span>        assertEquals(algo == GZ ? 2173 : 4936, <a name="line.108"></a>
<span class="sourceLineNo">109</span>                     b.getOnDiskSizeWithoutHeader() - b.totalChecksumBytes());<a name="line.109"></a>
<span class="sourceLineNo">110</span>        // read data back from the hfile, exclude header and checksum<a name="line.110"></a>
<span class="sourceLineNo">111</span>        ByteBuffer bb = b.getBufferWithoutHeader(); // read back data<a name="line.111"></a>
<span class="sourceLineNo">112</span>        DataInputStream in = new DataInputStream(<a name="line.112"></a>
<span class="sourceLineNo">113</span>                               new ByteArrayInputStream(<a name="line.113"></a>
<span class="sourceLineNo">114</span>                                 bb.array(), bb.arrayOffset(), bb.limit()));<a name="line.114"></a>
<span class="sourceLineNo">115</span><a name="line.115"></a>
<span class="sourceLineNo">116</span>        // assert that we encountered hbase checksum verification failures<a name="line.116"></a>
<span class="sourceLineNo">117</span>        // but still used hdfs checksums and read data successfully.<a name="line.117"></a>
<span class="sourceLineNo">118</span>        assertEquals(1, HFile.getChecksumFailuresCount());<a name="line.118"></a>
<span class="sourceLineNo">119</span>        validateData(in);<a name="line.119"></a>
<span class="sourceLineNo">120</span><a name="line.120"></a>
<span class="sourceLineNo">121</span>        // A single instance of hbase checksum failure causes the reader to<a name="line.121"></a>
<span class="sourceLineNo">122</span>        // switch off hbase checksum verification for the next 100 read<a name="line.122"></a>
<span class="sourceLineNo">123</span>        // requests. Verify that this is correct.<a name="line.123"></a>
<span class="sourceLineNo">124</span>        for (int i = 0; i &lt; <a name="line.124"></a>
<span class="sourceLineNo">125</span>             HFileBlock.CHECKSUM_VERIFICATION_NUM_IO_THRESHOLD + 1; i++) {<a name="line.125"></a>
<span class="sourceLineNo">126</span>          b = hbr.readBlockData(0, -1, -1, pread);<a name="line.126"></a>
<span class="sourceLineNo">127</span>          assertEquals(0, HFile.getChecksumFailuresCount());<a name="line.127"></a>
<span class="sourceLineNo">128</span>        }<a name="line.128"></a>
<span class="sourceLineNo">129</span>        // The next read should have hbase checksum verification reanabled,<a name="line.129"></a>
<span class="sourceLineNo">130</span>        // we verify this by assertng that there was a hbase-checksum failure.<a name="line.130"></a>
<span class="sourceLineNo">131</span>        b = hbr.readBlockData(0, -1, -1, pread);<a name="line.131"></a>
<span class="sourceLineNo">132</span>        assertEquals(1, HFile.getChecksumFailuresCount());<a name="line.132"></a>
<span class="sourceLineNo">133</span><a name="line.133"></a>
<span class="sourceLineNo">134</span>        // Since the above encountered a checksum failure, we switch<a name="line.134"></a>
<span class="sourceLineNo">135</span>        // back to not checking hbase checksums.<a name="line.135"></a>
<span class="sourceLineNo">136</span>        b = hbr.readBlockData(0, -1, -1, pread);<a name="line.136"></a>
<span class="sourceLineNo">137</span>        assertEquals(0, HFile.getChecksumFailuresCount());<a name="line.137"></a>
<span class="sourceLineNo">138</span>        is.close();<a name="line.138"></a>
<span class="sourceLineNo">139</span><a name="line.139"></a>
<span class="sourceLineNo">140</span>        // Now, use a completely new reader. Switch off hbase checksums in <a name="line.140"></a>
<span class="sourceLineNo">141</span>        // the configuration. In this case, we should not detect<a name="line.141"></a>
<span class="sourceLineNo">142</span>        // any retries within hbase. <a name="line.142"></a>
<span class="sourceLineNo">143</span>        HFileSystem newfs = new HFileSystem(TEST_UTIL.getConfiguration(), false);<a name="line.143"></a>
<span class="sourceLineNo">144</span>        assertEquals(false, newfs.useHBaseChecksum());<a name="line.144"></a>
<span class="sourceLineNo">145</span>        is = newfs.open(path);<a name="line.145"></a>
<span class="sourceLineNo">146</span>        hbr = new FSReaderV2Test(is, algo,<a name="line.146"></a>
<span class="sourceLineNo">147</span>            totalSize, HFile.MAX_FORMAT_VERSION, newfs, path);<a name="line.147"></a>
<span class="sourceLineNo">148</span>        b = hbr.readBlockData(0, -1, -1, pread);<a name="line.148"></a>
<span class="sourceLineNo">149</span>        is.close();<a name="line.149"></a>
<span class="sourceLineNo">150</span>        b.sanityCheck();<a name="line.150"></a>
<span class="sourceLineNo">151</span>        assertEquals(4936, b.getUncompressedSizeWithoutHeader());<a name="line.151"></a>
<span class="sourceLineNo">152</span>        assertEquals(algo == GZ ? 2173 : 4936, <a name="line.152"></a>
<span class="sourceLineNo">153</span>                     b.getOnDiskSizeWithoutHeader() - b.totalChecksumBytes());<a name="line.153"></a>
<span class="sourceLineNo">154</span>        // read data back from the hfile, exclude header and checksum<a name="line.154"></a>
<span class="sourceLineNo">155</span>        bb = b.getBufferWithoutHeader(); // read back data<a name="line.155"></a>
<span class="sourceLineNo">156</span>        in = new DataInputStream(new ByteArrayInputStream(<a name="line.156"></a>
<span class="sourceLineNo">157</span>                                 bb.array(), bb.arrayOffset(), bb.limit()));<a name="line.157"></a>
<span class="sourceLineNo">158</span><a name="line.158"></a>
<span class="sourceLineNo">159</span>        // assert that we did not encounter hbase checksum verification failures<a name="line.159"></a>
<span class="sourceLineNo">160</span>        // but still used hdfs checksums and read data successfully.<a name="line.160"></a>
<span class="sourceLineNo">161</span>        assertEquals(0, HFile.getChecksumFailuresCount());<a name="line.161"></a>
<span class="sourceLineNo">162</span>        validateData(in);<a name="line.162"></a>
<span class="sourceLineNo">163</span>      }<a name="line.163"></a>
<span class="sourceLineNo">164</span>    }<a name="line.164"></a>
<span class="sourceLineNo">165</span>  }<a name="line.165"></a>
<span class="sourceLineNo">166</span><a name="line.166"></a>
<span class="sourceLineNo">167</span>  /** <a name="line.167"></a>
<span class="sourceLineNo">168</span>   * Test different values of bytesPerChecksum<a name="line.168"></a>
<span class="sourceLineNo">169</span>   */<a name="line.169"></a>
<span class="sourceLineNo">170</span>  @Test<a name="line.170"></a>
<span class="sourceLineNo">171</span>  public void testChecksumChunks() throws IOException {<a name="line.171"></a>
<span class="sourceLineNo">172</span>    Compression.Algorithm algo = NONE;<a name="line.172"></a>
<span class="sourceLineNo">173</span>    for (boolean pread : new boolean[] { false, true }) {<a name="line.173"></a>
<span class="sourceLineNo">174</span>      for (int bytesPerChecksum : BYTES_PER_CHECKSUM) {<a name="line.174"></a>
<span class="sourceLineNo">175</span>        Path path = new Path(TEST_UTIL.getDataTestDir(), "checksumChunk_" + <a name="line.175"></a>
<span class="sourceLineNo">176</span>                             algo + bytesPerChecksum);<a name="line.176"></a>
<span class="sourceLineNo">177</span>        FSDataOutputStream os = fs.create(path);<a name="line.177"></a>
<span class="sourceLineNo">178</span>        HFileBlock.Writer hbw = new HFileBlock.Writer(algo, null,<a name="line.178"></a>
<span class="sourceLineNo">179</span>          true, 1,HFile.DEFAULT_CHECKSUM_TYPE, bytesPerChecksum);<a name="line.179"></a>
<span class="sourceLineNo">180</span><a name="line.180"></a>
<span class="sourceLineNo">181</span>        // write one block. The block has data<a name="line.181"></a>
<span class="sourceLineNo">182</span>        // that is at least 6 times more than the checksum chunk size<a name="line.182"></a>
<span class="sourceLineNo">183</span>        long dataSize = 0;<a name="line.183"></a>
<span class="sourceLineNo">184</span>        DataOutputStream dos = hbw.startWriting(BlockType.DATA);<a name="line.184"></a>
<span class="sourceLineNo">185</span>        for (; dataSize &lt; 6 * bytesPerChecksum;) {<a name="line.185"></a>
<span class="sourceLineNo">186</span>          for (int i = 0; i &lt; 1234; ++i) {<a name="line.186"></a>
<span class="sourceLineNo">187</span>            dos.writeInt(i);<a name="line.187"></a>
<span class="sourceLineNo">188</span>            dataSize += 4;<a name="line.188"></a>
<span class="sourceLineNo">189</span>          }<a name="line.189"></a>
<span class="sourceLineNo">190</span>        }<a name="line.190"></a>
<span class="sourceLineNo">191</span>        hbw.writeHeaderAndData(os);<a name="line.191"></a>
<span class="sourceLineNo">192</span>        long totalSize = hbw.getOnDiskSizeWithHeader();<a name="line.192"></a>
<span class="sourceLineNo">193</span>        os.close();<a name="line.193"></a>
<span class="sourceLineNo">194</span><a name="line.194"></a>
<span class="sourceLineNo">195</span>        long expectedChunks = ChecksumUtil.numChunks(<a name="line.195"></a>
<span class="sourceLineNo">196</span>                               dataSize + HFileBlock.HEADER_SIZE_WITH_CHECKSUMS,<a name="line.196"></a>
<span class="sourceLineNo">197</span>                               bytesPerChecksum);<a name="line.197"></a>
<span class="sourceLineNo">198</span>        LOG.info("testChecksumChunks: pread=" + pread +<a name="line.198"></a>
<span class="sourceLineNo">199</span>                   ", bytesPerChecksum=" + bytesPerChecksum +<a name="line.199"></a>
<span class="sourceLineNo">200</span>                   ", fileSize=" + totalSize +<a name="line.200"></a>
<span class="sourceLineNo">201</span>                   ", dataSize=" + dataSize +<a name="line.201"></a>
<span class="sourceLineNo">202</span>                   ", expectedChunks=" + expectedChunks);<a name="line.202"></a>
<span class="sourceLineNo">203</span><a name="line.203"></a>
<span class="sourceLineNo">204</span>        // Verify hbase checksums. <a name="line.204"></a>
<span class="sourceLineNo">205</span>        assertEquals(true, hfs.useHBaseChecksum());<a name="line.205"></a>
<span class="sourceLineNo">206</span><a name="line.206"></a>
<span class="sourceLineNo">207</span>        // Read data back from file.<a name="line.207"></a>
<span class="sourceLineNo">208</span>        FSDataInputStream is = fs.open(path);<a name="line.208"></a>
<span class="sourceLineNo">209</span>        FSDataInputStream nochecksum = hfs.getNoChecksumFs().open(path);<a name="line.209"></a>
<span class="sourceLineNo">210</span>        HFileBlock.FSReader hbr = new HFileBlock.FSReaderV2(is, nochecksum, <a name="line.210"></a>
<span class="sourceLineNo">211</span>            algo, totalSize, HFile.MAX_FORMAT_VERSION, hfs, path);<a name="line.211"></a>
<span class="sourceLineNo">212</span>        HFileBlock b = hbr.readBlockData(0, -1, -1, pread);<a name="line.212"></a>
<span class="sourceLineNo">213</span>        is.close();<a name="line.213"></a>
<span class="sourceLineNo">214</span>        b.sanityCheck();<a name="line.214"></a>
<span class="sourceLineNo">215</span>        assertEquals(dataSize, b.getUncompressedSizeWithoutHeader());<a name="line.215"></a>
<span class="sourceLineNo">216</span><a name="line.216"></a>
<span class="sourceLineNo">217</span>        // verify that we have the expected number of checksum chunks<a name="line.217"></a>
<span class="sourceLineNo">218</span>        assertEquals(totalSize, HFileBlock.HEADER_SIZE_WITH_CHECKSUMS + dataSize +<a name="line.218"></a>
<span class="sourceLineNo">219</span>                     expectedChunks * HFileBlock.CHECKSUM_SIZE);<a name="line.219"></a>
<span class="sourceLineNo">220</span><a name="line.220"></a>
<span class="sourceLineNo">221</span>        // assert that we did not encounter hbase checksum verification failures<a name="line.221"></a>
<span class="sourceLineNo">222</span>        assertEquals(0, HFile.getChecksumFailuresCount());<a name="line.222"></a>
<span class="sourceLineNo">223</span>      }<a name="line.223"></a>
<span class="sourceLineNo">224</span>    }<a name="line.224"></a>
<span class="sourceLineNo">225</span>  }<a name="line.225"></a>
<span class="sourceLineNo">226</span><a name="line.226"></a>
<span class="sourceLineNo">227</span>  /** <a name="line.227"></a>
<span class="sourceLineNo">228</span>   * Test to ensure that these is at least one valid checksum implementation<a name="line.228"></a>
<span class="sourceLineNo">229</span>   */<a name="line.229"></a>
<span class="sourceLineNo">230</span>  @Test<a name="line.230"></a>
<span class="sourceLineNo">231</span>  public void testChecksumAlgorithm() throws IOException {<a name="line.231"></a>
<span class="sourceLineNo">232</span>    ChecksumType type = ChecksumType.CRC32;<a name="line.232"></a>
<span class="sourceLineNo">233</span>    assertEquals(ChecksumType.nameToType(type.getName()), type);<a name="line.233"></a>
<span class="sourceLineNo">234</span>    assertEquals(ChecksumType.valueOf(type.toString()), type);<a name="line.234"></a>
<span class="sourceLineNo">235</span>  }<a name="line.235"></a>
<span class="sourceLineNo">236</span><a name="line.236"></a>
<span class="sourceLineNo">237</span>  private void validateData(DataInputStream in) throws IOException {<a name="line.237"></a>
<span class="sourceLineNo">238</span>    // validate data<a name="line.238"></a>
<span class="sourceLineNo">239</span>    for (int i = 0; i &lt; 1234; i++) {<a name="line.239"></a>
<span class="sourceLineNo">240</span>      int val = in.readInt();<a name="line.240"></a>
<span class="sourceLineNo">241</span>      if (val != i) {<a name="line.241"></a>
<span class="sourceLineNo">242</span>        String msg = "testChecksumCorruption: data mismatch at index " +<a name="line.242"></a>
<span class="sourceLineNo">243</span>                     i + " expected " + i + " found " + val;<a name="line.243"></a>
<span class="sourceLineNo">244</span>        LOG.warn(msg);<a name="line.244"></a>
<span class="sourceLineNo">245</span>        assertEquals(i, val);<a name="line.245"></a>
<span class="sourceLineNo">246</span>      }<a name="line.246"></a>
<span class="sourceLineNo">247</span>    }<a name="line.247"></a>
<span class="sourceLineNo">248</span>  }<a name="line.248"></a>
<span class="sourceLineNo">249</span><a name="line.249"></a>
<span class="sourceLineNo">250</span>  @org.junit.Rule<a name="line.250"></a>
<span class="sourceLineNo">251</span>  public org.apache.hadoop.hbase.ResourceCheckerJUnitRule cu =<a name="line.251"></a>
<span class="sourceLineNo">252</span>    new org.apache.hadoop.hbase.ResourceCheckerJUnitRule();<a name="line.252"></a>
<span class="sourceLineNo">253</span><a name="line.253"></a>
<span class="sourceLineNo">254</span>  /**<a name="line.254"></a>
<span class="sourceLineNo">255</span>   * A class that introduces hbase-checksum failures while <a name="line.255"></a>
<span class="sourceLineNo">256</span>   * reading  data from hfiles. This should trigger the hdfs level<a name="line.256"></a>
<span class="sourceLineNo">257</span>   * checksum validations.<a name="line.257"></a>
<span class="sourceLineNo">258</span>   */<a name="line.258"></a>
<span class="sourceLineNo">259</span>  static private class FSReaderV2Test extends HFileBlock.FSReaderV2 {<a name="line.259"></a>
<span class="sourceLineNo">260</span><a name="line.260"></a>
<span class="sourceLineNo">261</span>    FSReaderV2Test(FSDataInputStream istream, Algorithm algo,<a name="line.261"></a>
<span class="sourceLineNo">262</span>                   long fileSize, int minorVersion, FileSystem fs,<a name="line.262"></a>
<span class="sourceLineNo">263</span>                   Path path) throws IOException {<a name="line.263"></a>
<span class="sourceLineNo">264</span>      super(istream, istream, algo, fileSize, minorVersion, <a name="line.264"></a>
<span class="sourceLineNo">265</span>            (HFileSystem)fs, path);<a name="line.265"></a>
<span class="sourceLineNo">266</span>    }<a name="line.266"></a>
<span class="sourceLineNo">267</span><a name="line.267"></a>
<span class="sourceLineNo">268</span>    @Override<a name="line.268"></a>
<span class="sourceLineNo">269</span>    protected boolean validateBlockChecksum(HFileBlock block, <a name="line.269"></a>
<span class="sourceLineNo">270</span>      byte[] data, int hdrSize) throws IOException {<a name="line.270"></a>
<span class="sourceLineNo">271</span>      return false;  // checksum validation failure<a name="line.271"></a>
<span class="sourceLineNo">272</span>    }<a name="line.272"></a>
<span class="sourceLineNo">273</span>  }<a name="line.273"></a>
<span class="sourceLineNo">274</span>}<a name="line.274"></a>
<span class="sourceLineNo">275</span><a name="line.275"></a>




























































</pre>
</div>
</body>
</html>
