<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en">
<head>
<title>Source code</title>
<link rel="stylesheet" type="text/css" href="../../../../../../stylesheet.css" title="Style">
</head>
<body>
<div class="sourceContainer">
<pre><span class="sourceLineNo">001</span>/*<a name="line.1"></a>
<span class="sourceLineNo">002</span> * Copyright 2011 The Apache Software Foundation<a name="line.2"></a>
<span class="sourceLineNo">003</span> *<a name="line.3"></a>
<span class="sourceLineNo">004</span> * Licensed to the Apache Software Foundation (ASF) under one<a name="line.4"></a>
<span class="sourceLineNo">005</span> * or more contributor license agreements.  See the NOTICE file<a name="line.5"></a>
<span class="sourceLineNo">006</span> * distributed with this work for additional information<a name="line.6"></a>
<span class="sourceLineNo">007</span> * regarding copyright ownership.  The ASF licenses this file<a name="line.7"></a>
<span class="sourceLineNo">008</span> * to you under the Apache License, Version 2.0 (the<a name="line.8"></a>
<span class="sourceLineNo">009</span> * "License"); you may not use this file except in compliance<a name="line.9"></a>
<span class="sourceLineNo">010</span> * with the License.  You may obtain a copy of the License at<a name="line.10"></a>
<span class="sourceLineNo">011</span> *<a name="line.11"></a>
<span class="sourceLineNo">012</span> *     http://www.apache.org/licenses/LICENSE-2.0<a name="line.12"></a>
<span class="sourceLineNo">013</span> *<a name="line.13"></a>
<span class="sourceLineNo">014</span> * Unless required by applicable law or agreed to in writing, software<a name="line.14"></a>
<span class="sourceLineNo">015</span> * distributed under the License is distributed on an "AS IS" BASIS,<a name="line.15"></a>
<span class="sourceLineNo">016</span> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<a name="line.16"></a>
<span class="sourceLineNo">017</span> * See the License for the specific language governing permissions and<a name="line.17"></a>
<span class="sourceLineNo">018</span> * limitations under the License.<a name="line.18"></a>
<span class="sourceLineNo">019</span> */<a name="line.19"></a>
<span class="sourceLineNo">020</span><a name="line.20"></a>
<span class="sourceLineNo">021</span>package org.apache.hadoop.hbase.regionserver;<a name="line.21"></a>
<span class="sourceLineNo">022</span><a name="line.22"></a>
<span class="sourceLineNo">023</span>import static org.junit.Assert.*;<a name="line.23"></a>
<span class="sourceLineNo">024</span><a name="line.24"></a>
<span class="sourceLineNo">025</span>import java.io.IOException;<a name="line.25"></a>
<span class="sourceLineNo">026</span>import java.util.ArrayList;<a name="line.26"></a>
<span class="sourceLineNo">027</span>import java.util.Collection;<a name="line.27"></a>
<span class="sourceLineNo">028</span>import java.util.List;<a name="line.28"></a>
<span class="sourceLineNo">029</span>import java.util.Random;<a name="line.29"></a>
<span class="sourceLineNo">030</span><a name="line.30"></a>
<span class="sourceLineNo">031</span>import org.apache.commons.logging.Log;<a name="line.31"></a>
<span class="sourceLineNo">032</span>import org.apache.commons.logging.LogFactory;<a name="line.32"></a>
<span class="sourceLineNo">033</span>import org.apache.hadoop.conf.Configuration;<a name="line.33"></a>
<span class="sourceLineNo">034</span>import org.apache.hadoop.fs.FileSystem;<a name="line.34"></a>
<span class="sourceLineNo">035</span>import org.apache.hadoop.fs.Path;<a name="line.35"></a>
<span class="sourceLineNo">036</span>import org.apache.hadoop.hbase.HBaseTestingUtility;<a name="line.36"></a>
<span class="sourceLineNo">037</span>import org.apache.hadoop.hbase.HColumnDescriptor;<a name="line.37"></a>
<span class="sourceLineNo">038</span>import org.apache.hadoop.hbase.HConstants;<a name="line.38"></a>
<span class="sourceLineNo">039</span>import org.apache.hadoop.hbase.HRegionInfo;<a name="line.39"></a>
<span class="sourceLineNo">040</span>import org.apache.hadoop.hbase.HTableDescriptor;<a name="line.40"></a>
<span class="sourceLineNo">041</span>import org.apache.hadoop.hbase.KeyValue;<a name="line.41"></a>
<span class="sourceLineNo">042</span>import org.apache.hadoop.hbase.MediumTests;<a name="line.42"></a>
<span class="sourceLineNo">043</span>import org.apache.hadoop.hbase.fs.HFileSystem;<a name="line.43"></a>
<span class="sourceLineNo">044</span>import org.apache.hadoop.hbase.io.hfile.BlockCache;<a name="line.44"></a>
<span class="sourceLineNo">045</span>import org.apache.hadoop.hbase.io.hfile.BlockCacheKey;<a name="line.45"></a>
<span class="sourceLineNo">046</span>import org.apache.hadoop.hbase.io.hfile.BlockType;<a name="line.46"></a>
<span class="sourceLineNo">047</span>import org.apache.hadoop.hbase.io.hfile.CacheConfig;<a name="line.47"></a>
<span class="sourceLineNo">048</span>import org.apache.hadoop.hbase.io.hfile.Compression;<a name="line.48"></a>
<span class="sourceLineNo">049</span>import org.apache.hadoop.hbase.io.hfile.HFile;<a name="line.49"></a>
<span class="sourceLineNo">050</span>import org.apache.hadoop.hbase.io.hfile.HFileBlock;<a name="line.50"></a>
<span class="sourceLineNo">051</span>import org.apache.hadoop.hbase.io.hfile.HFileReaderV2;<a name="line.51"></a>
<span class="sourceLineNo">052</span>import org.apache.hadoop.hbase.io.hfile.HFileScanner;<a name="line.52"></a>
<span class="sourceLineNo">053</span>import org.apache.hadoop.hbase.io.hfile.TestHFileWriterV2;<a name="line.53"></a>
<span class="sourceLineNo">054</span>import org.apache.hadoop.hbase.regionserver.StoreFile.BloomType;<a name="line.54"></a>
<span class="sourceLineNo">055</span>import org.apache.hadoop.hbase.regionserver.wal.HLog;<a name="line.55"></a>
<span class="sourceLineNo">056</span>import org.apache.hadoop.hbase.util.Bytes;<a name="line.56"></a>
<span class="sourceLineNo">057</span><a name="line.57"></a>
<span class="sourceLineNo">058</span>import org.junit.After;<a name="line.58"></a>
<span class="sourceLineNo">059</span>import org.junit.Before;<a name="line.59"></a>
<span class="sourceLineNo">060</span>import org.junit.Test;<a name="line.60"></a>
<span class="sourceLineNo">061</span>import org.junit.experimental.categories.Category;<a name="line.61"></a>
<span class="sourceLineNo">062</span>import org.junit.runner.RunWith;<a name="line.62"></a>
<span class="sourceLineNo">063</span>import org.junit.runners.Parameterized;<a name="line.63"></a>
<span class="sourceLineNo">064</span>import org.junit.runners.Parameterized.Parameters;<a name="line.64"></a>
<span class="sourceLineNo">065</span><a name="line.65"></a>
<span class="sourceLineNo">066</span>/**<a name="line.66"></a>
<span class="sourceLineNo">067</span> * Tests {@link HFile} cache-on-write functionality for data blocks, non-root<a name="line.67"></a>
<span class="sourceLineNo">068</span> * index blocks, and Bloom filter blocks, as specified by the column family. <a name="line.68"></a>
<span class="sourceLineNo">069</span> */<a name="line.69"></a>
<span class="sourceLineNo">070</span>@RunWith(Parameterized.class)<a name="line.70"></a>
<span class="sourceLineNo">071</span>@Category(MediumTests.class)<a name="line.71"></a>
<span class="sourceLineNo">072</span>public class TestCacheOnWriteInSchema {<a name="line.72"></a>
<span class="sourceLineNo">073</span><a name="line.73"></a>
<span class="sourceLineNo">074</span>  private static final Log LOG = LogFactory.getLog(TestCacheOnWriteInSchema.class);<a name="line.74"></a>
<span class="sourceLineNo">075</span><a name="line.75"></a>
<span class="sourceLineNo">076</span>  private static final HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();<a name="line.76"></a>
<span class="sourceLineNo">077</span>  private static final String DIR = TEST_UTIL.getDataTestDir("TestCacheOnWriteInSchema").toString();<a name="line.77"></a>
<span class="sourceLineNo">078</span>  private static final byte [] table = Bytes.toBytes("table");<a name="line.78"></a>
<span class="sourceLineNo">079</span>  private static byte [] family = Bytes.toBytes("family");<a name="line.79"></a>
<span class="sourceLineNo">080</span>  private static final int NUM_KV = 25000;<a name="line.80"></a>
<span class="sourceLineNo">081</span>  private static final Random rand = new Random(12983177L);<a name="line.81"></a>
<span class="sourceLineNo">082</span>  /** The number of valid key types possible in a store file */<a name="line.82"></a>
<span class="sourceLineNo">083</span>  private static final int NUM_VALID_KEY_TYPES =<a name="line.83"></a>
<span class="sourceLineNo">084</span>      KeyValue.Type.values().length - 2;<a name="line.84"></a>
<span class="sourceLineNo">085</span><a name="line.85"></a>
<span class="sourceLineNo">086</span>  private static enum CacheOnWriteType {<a name="line.86"></a>
<span class="sourceLineNo">087</span>    DATA_BLOCKS(BlockType.DATA, BlockType.ENCODED_DATA),<a name="line.87"></a>
<span class="sourceLineNo">088</span>    BLOOM_BLOCKS(BlockType.BLOOM_CHUNK),<a name="line.88"></a>
<span class="sourceLineNo">089</span>    INDEX_BLOCKS(BlockType.LEAF_INDEX, BlockType.INTERMEDIATE_INDEX);<a name="line.89"></a>
<span class="sourceLineNo">090</span><a name="line.90"></a>
<span class="sourceLineNo">091</span>    private final BlockType blockType1;<a name="line.91"></a>
<span class="sourceLineNo">092</span>    private final BlockType blockType2;<a name="line.92"></a>
<span class="sourceLineNo">093</span><a name="line.93"></a>
<span class="sourceLineNo">094</span>    private CacheOnWriteType(BlockType blockType) {<a name="line.94"></a>
<span class="sourceLineNo">095</span>      this(blockType, blockType);<a name="line.95"></a>
<span class="sourceLineNo">096</span>    }<a name="line.96"></a>
<span class="sourceLineNo">097</span><a name="line.97"></a>
<span class="sourceLineNo">098</span>    private CacheOnWriteType(BlockType blockType1, BlockType blockType2) {<a name="line.98"></a>
<span class="sourceLineNo">099</span>      this.blockType1 = blockType1;<a name="line.99"></a>
<span class="sourceLineNo">100</span>      this.blockType2 = blockType2;<a name="line.100"></a>
<span class="sourceLineNo">101</span>    }<a name="line.101"></a>
<span class="sourceLineNo">102</span><a name="line.102"></a>
<span class="sourceLineNo">103</span>    public boolean shouldBeCached(BlockType blockType) {<a name="line.103"></a>
<span class="sourceLineNo">104</span>      return blockType == blockType1 || blockType == blockType2;<a name="line.104"></a>
<span class="sourceLineNo">105</span>    }<a name="line.105"></a>
<span class="sourceLineNo">106</span><a name="line.106"></a>
<span class="sourceLineNo">107</span>    public void modifyFamilySchema(HColumnDescriptor family) {<a name="line.107"></a>
<span class="sourceLineNo">108</span>      switch (this) {<a name="line.108"></a>
<span class="sourceLineNo">109</span>      case DATA_BLOCKS:<a name="line.109"></a>
<span class="sourceLineNo">110</span>        family.setCacheDataOnWrite(true);<a name="line.110"></a>
<span class="sourceLineNo">111</span>        break;<a name="line.111"></a>
<span class="sourceLineNo">112</span>      case BLOOM_BLOCKS:<a name="line.112"></a>
<span class="sourceLineNo">113</span>        family.setCacheBloomsOnWrite(true);<a name="line.113"></a>
<span class="sourceLineNo">114</span>        break;<a name="line.114"></a>
<span class="sourceLineNo">115</span>      case INDEX_BLOCKS:<a name="line.115"></a>
<span class="sourceLineNo">116</span>        family.setCacheIndexesOnWrite(true);<a name="line.116"></a>
<span class="sourceLineNo">117</span>        break;<a name="line.117"></a>
<span class="sourceLineNo">118</span>      }<a name="line.118"></a>
<span class="sourceLineNo">119</span>    }<a name="line.119"></a>
<span class="sourceLineNo">120</span>  }<a name="line.120"></a>
<span class="sourceLineNo">121</span><a name="line.121"></a>
<span class="sourceLineNo">122</span>  private final CacheOnWriteType cowType;<a name="line.122"></a>
<span class="sourceLineNo">123</span>  private Configuration conf;<a name="line.123"></a>
<span class="sourceLineNo">124</span>  private final String testDescription;<a name="line.124"></a>
<span class="sourceLineNo">125</span>  private Store store;<a name="line.125"></a>
<span class="sourceLineNo">126</span>  private FileSystem fs;<a name="line.126"></a>
<span class="sourceLineNo">127</span><a name="line.127"></a>
<span class="sourceLineNo">128</span>  public TestCacheOnWriteInSchema(CacheOnWriteType cowType) {<a name="line.128"></a>
<span class="sourceLineNo">129</span>    this.cowType = cowType;<a name="line.129"></a>
<span class="sourceLineNo">130</span>    testDescription = "[cacheOnWrite=" + cowType + "]";<a name="line.130"></a>
<span class="sourceLineNo">131</span>    System.out.println(testDescription);<a name="line.131"></a>
<span class="sourceLineNo">132</span>  }<a name="line.132"></a>
<span class="sourceLineNo">133</span><a name="line.133"></a>
<span class="sourceLineNo">134</span>  @Parameters<a name="line.134"></a>
<span class="sourceLineNo">135</span>  public static Collection&lt;Object[]&gt; getParameters() {<a name="line.135"></a>
<span class="sourceLineNo">136</span>    List&lt;Object[]&gt; cowTypes = new ArrayList&lt;Object[]&gt;();<a name="line.136"></a>
<span class="sourceLineNo">137</span>    for (CacheOnWriteType cowType : CacheOnWriteType.values()) {<a name="line.137"></a>
<span class="sourceLineNo">138</span>      cowTypes.add(new Object[] { cowType });<a name="line.138"></a>
<span class="sourceLineNo">139</span>    }<a name="line.139"></a>
<span class="sourceLineNo">140</span>    return cowTypes;<a name="line.140"></a>
<span class="sourceLineNo">141</span>  }<a name="line.141"></a>
<span class="sourceLineNo">142</span><a name="line.142"></a>
<span class="sourceLineNo">143</span>  @Before<a name="line.143"></a>
<span class="sourceLineNo">144</span>  public void setUp() throws IOException {<a name="line.144"></a>
<span class="sourceLineNo">145</span>    conf = TEST_UTIL.getConfiguration();<a name="line.145"></a>
<span class="sourceLineNo">146</span>    conf.setInt(HFile.FORMAT_VERSION_KEY, HFile.MAX_FORMAT_VERSION);<a name="line.146"></a>
<span class="sourceLineNo">147</span>    conf.setBoolean(CacheConfig.CACHE_BLOCKS_ON_WRITE_KEY, false);<a name="line.147"></a>
<span class="sourceLineNo">148</span>    conf.setBoolean(CacheConfig.CACHE_INDEX_BLOCKS_ON_WRITE_KEY, false);<a name="line.148"></a>
<span class="sourceLineNo">149</span>    conf.setBoolean(CacheConfig.CACHE_BLOOM_BLOCKS_ON_WRITE_KEY, false);<a name="line.149"></a>
<span class="sourceLineNo">150</span><a name="line.150"></a>
<span class="sourceLineNo">151</span>    fs = HFileSystem.get(conf);<a name="line.151"></a>
<span class="sourceLineNo">152</span><a name="line.152"></a>
<span class="sourceLineNo">153</span>    // Create the schema<a name="line.153"></a>
<span class="sourceLineNo">154</span>    HColumnDescriptor hcd = new HColumnDescriptor(family);<a name="line.154"></a>
<span class="sourceLineNo">155</span>    hcd.setBloomFilterType(BloomType.ROWCOL);<a name="line.155"></a>
<span class="sourceLineNo">156</span>    cowType.modifyFamilySchema(hcd);<a name="line.156"></a>
<span class="sourceLineNo">157</span>    HTableDescriptor htd = new HTableDescriptor(table);<a name="line.157"></a>
<span class="sourceLineNo">158</span>    htd.addFamily(hcd);<a name="line.158"></a>
<span class="sourceLineNo">159</span><a name="line.159"></a>
<span class="sourceLineNo">160</span>    // Create a store based on the schema<a name="line.160"></a>
<span class="sourceLineNo">161</span>    Path basedir = new Path(DIR);<a name="line.161"></a>
<span class="sourceLineNo">162</span>    Path logdir = new Path(DIR+"/logs");<a name="line.162"></a>
<span class="sourceLineNo">163</span>    Path oldLogDir = new Path(basedir, HConstants.HREGION_OLDLOGDIR_NAME);<a name="line.163"></a>
<span class="sourceLineNo">164</span>    fs.delete(logdir, true);<a name="line.164"></a>
<span class="sourceLineNo">165</span>    HRegionInfo info = new HRegionInfo(htd.getName(), null, null, false);<a name="line.165"></a>
<span class="sourceLineNo">166</span>    HLog hlog = new HLog(fs, logdir, oldLogDir, conf);<a name="line.166"></a>
<span class="sourceLineNo">167</span>    HRegion region = new HRegion(basedir, hlog, fs, conf, info, htd, null);<a name="line.167"></a>
<span class="sourceLineNo">168</span>    store = new Store(basedir, region, hcd, fs, conf);<a name="line.168"></a>
<span class="sourceLineNo">169</span>  }<a name="line.169"></a>
<span class="sourceLineNo">170</span><a name="line.170"></a>
<span class="sourceLineNo">171</span>  @After<a name="line.171"></a>
<span class="sourceLineNo">172</span>  public void tearDown() {<a name="line.172"></a>
<span class="sourceLineNo">173</span>    try {<a name="line.173"></a>
<span class="sourceLineNo">174</span>      fs.delete(new Path(DIR), true);<a name="line.174"></a>
<span class="sourceLineNo">175</span>    } catch (IOException e) {<a name="line.175"></a>
<span class="sourceLineNo">176</span>      LOG.error("Could not delete " + DIR, e);<a name="line.176"></a>
<span class="sourceLineNo">177</span>    }<a name="line.177"></a>
<span class="sourceLineNo">178</span>  }<a name="line.178"></a>
<span class="sourceLineNo">179</span><a name="line.179"></a>
<span class="sourceLineNo">180</span>  @Test<a name="line.180"></a>
<span class="sourceLineNo">181</span>  public void testCacheOnWriteInSchema() throws IOException {<a name="line.181"></a>
<span class="sourceLineNo">182</span>    // Write some random data into the store<a name="line.182"></a>
<span class="sourceLineNo">183</span>    StoreFile.Writer writer = store.createWriterInTmp(Integer.MAX_VALUE,<a name="line.183"></a>
<span class="sourceLineNo">184</span>        Compression.Algorithm.NONE, false, true);<a name="line.184"></a>
<span class="sourceLineNo">185</span>    writeStoreFile(writer);<a name="line.185"></a>
<span class="sourceLineNo">186</span>    writer.close();<a name="line.186"></a>
<span class="sourceLineNo">187</span>    // Verify the block types of interest were cached on write<a name="line.187"></a>
<span class="sourceLineNo">188</span>    readStoreFile(writer.getPath());<a name="line.188"></a>
<span class="sourceLineNo">189</span>  }<a name="line.189"></a>
<span class="sourceLineNo">190</span><a name="line.190"></a>
<span class="sourceLineNo">191</span>  private void readStoreFile(Path path) throws IOException {<a name="line.191"></a>
<span class="sourceLineNo">192</span>    CacheConfig cacheConf = store.getCacheConfig(); <a name="line.192"></a>
<span class="sourceLineNo">193</span>    BlockCache cache = cacheConf.getBlockCache();<a name="line.193"></a>
<span class="sourceLineNo">194</span>    StoreFile sf = new StoreFile(fs, path, conf, cacheConf,<a name="line.194"></a>
<span class="sourceLineNo">195</span>        BloomType.ROWCOL, null);<a name="line.195"></a>
<span class="sourceLineNo">196</span>    store.passSchemaMetricsTo(sf);<a name="line.196"></a>
<span class="sourceLineNo">197</span>    HFileReaderV2 reader = (HFileReaderV2) sf.createReader().getHFileReader();<a name="line.197"></a>
<span class="sourceLineNo">198</span>    try {<a name="line.198"></a>
<span class="sourceLineNo">199</span>      // Open a scanner with (on read) caching disabled<a name="line.199"></a>
<span class="sourceLineNo">200</span>      HFileScanner scanner = reader.getScanner(false, false);<a name="line.200"></a>
<span class="sourceLineNo">201</span>      assertTrue(testDescription, scanner.seekTo());<a name="line.201"></a>
<span class="sourceLineNo">202</span>      // Cribbed from io.hfile.TestCacheOnWrite<a name="line.202"></a>
<span class="sourceLineNo">203</span>      long offset = 0;<a name="line.203"></a>
<span class="sourceLineNo">204</span>      HFileBlock prevBlock = null;<a name="line.204"></a>
<span class="sourceLineNo">205</span>      while (offset &lt; reader.getTrailer().getLoadOnOpenDataOffset()) {<a name="line.205"></a>
<span class="sourceLineNo">206</span>        long onDiskSize = -1;<a name="line.206"></a>
<span class="sourceLineNo">207</span>        if (prevBlock != null) {<a name="line.207"></a>
<span class="sourceLineNo">208</span>          onDiskSize = prevBlock.getNextBlockOnDiskSizeWithHeader();<a name="line.208"></a>
<span class="sourceLineNo">209</span>        }<a name="line.209"></a>
<span class="sourceLineNo">210</span>        // Flags: don't cache the block, use pread, this is not a compaction.<a name="line.210"></a>
<span class="sourceLineNo">211</span>        // Also, pass null for expected block type to avoid checking it.<a name="line.211"></a>
<span class="sourceLineNo">212</span>        HFileBlock block = reader.readBlock(offset, onDiskSize, false, true,<a name="line.212"></a>
<span class="sourceLineNo">213</span>          false, null);<a name="line.213"></a>
<span class="sourceLineNo">214</span>        BlockCacheKey blockCacheKey = new BlockCacheKey(reader.getName(),<a name="line.214"></a>
<span class="sourceLineNo">215</span>          offset);<a name="line.215"></a>
<span class="sourceLineNo">216</span>        boolean isCached = cache.getBlock(blockCacheKey, true, false) != null;<a name="line.216"></a>
<span class="sourceLineNo">217</span>        boolean shouldBeCached = cowType.shouldBeCached(block.getBlockType());<a name="line.217"></a>
<span class="sourceLineNo">218</span>        if (shouldBeCached != isCached) {<a name="line.218"></a>
<span class="sourceLineNo">219</span>          throw new AssertionError(<a name="line.219"></a>
<span class="sourceLineNo">220</span>            "shouldBeCached: " + shouldBeCached+ "\n" +<a name="line.220"></a>
<span class="sourceLineNo">221</span>            "isCached: " + isCached + "\n" +<a name="line.221"></a>
<span class="sourceLineNo">222</span>            "Test description: " + testDescription + "\n" +<a name="line.222"></a>
<span class="sourceLineNo">223</span>            "block: " + block + "\n" +<a name="line.223"></a>
<span class="sourceLineNo">224</span>            "blockCacheKey: " + blockCacheKey);<a name="line.224"></a>
<span class="sourceLineNo">225</span>        }<a name="line.225"></a>
<span class="sourceLineNo">226</span>        prevBlock = block;<a name="line.226"></a>
<span class="sourceLineNo">227</span>        offset += block.getOnDiskSizeWithHeader();<a name="line.227"></a>
<span class="sourceLineNo">228</span>      }<a name="line.228"></a>
<span class="sourceLineNo">229</span>    } finally {<a name="line.229"></a>
<span class="sourceLineNo">230</span>      reader.close();<a name="line.230"></a>
<span class="sourceLineNo">231</span>    }<a name="line.231"></a>
<span class="sourceLineNo">232</span>  }<a name="line.232"></a>
<span class="sourceLineNo">233</span><a name="line.233"></a>
<span class="sourceLineNo">234</span>  private static KeyValue.Type generateKeyType(Random rand) {<a name="line.234"></a>
<span class="sourceLineNo">235</span>    if (rand.nextBoolean()) {<a name="line.235"></a>
<span class="sourceLineNo">236</span>      // Let's make half of KVs puts.<a name="line.236"></a>
<span class="sourceLineNo">237</span>      return KeyValue.Type.Put;<a name="line.237"></a>
<span class="sourceLineNo">238</span>    } else {<a name="line.238"></a>
<span class="sourceLineNo">239</span>      KeyValue.Type keyType =<a name="line.239"></a>
<span class="sourceLineNo">240</span>          KeyValue.Type.values()[1 + rand.nextInt(NUM_VALID_KEY_TYPES)];<a name="line.240"></a>
<span class="sourceLineNo">241</span>      if (keyType == KeyValue.Type.Minimum || keyType == KeyValue.Type.Maximum)<a name="line.241"></a>
<span class="sourceLineNo">242</span>      {<a name="line.242"></a>
<span class="sourceLineNo">243</span>        throw new RuntimeException("Generated an invalid key type: " + keyType<a name="line.243"></a>
<span class="sourceLineNo">244</span>            + ". " + "Probably the layout of KeyValue.Type has changed.");<a name="line.244"></a>
<span class="sourceLineNo">245</span>      }<a name="line.245"></a>
<span class="sourceLineNo">246</span>      return keyType;<a name="line.246"></a>
<span class="sourceLineNo">247</span>    }<a name="line.247"></a>
<span class="sourceLineNo">248</span>  }<a name="line.248"></a>
<span class="sourceLineNo">249</span><a name="line.249"></a>
<span class="sourceLineNo">250</span>  private void writeStoreFile(StoreFile.Writer writer) throws IOException {<a name="line.250"></a>
<span class="sourceLineNo">251</span>    final int rowLen = 32;<a name="line.251"></a>
<span class="sourceLineNo">252</span>    for (int i = 0; i &lt; NUM_KV; ++i) {<a name="line.252"></a>
<span class="sourceLineNo">253</span>      byte[] k = TestHFileWriterV2.randomOrderedKey(rand, i);<a name="line.253"></a>
<span class="sourceLineNo">254</span>      byte[] v = TestHFileWriterV2.randomValue(rand);<a name="line.254"></a>
<span class="sourceLineNo">255</span>      int cfLen = rand.nextInt(k.length - rowLen + 1);<a name="line.255"></a>
<span class="sourceLineNo">256</span>      KeyValue kv = new KeyValue(<a name="line.256"></a>
<span class="sourceLineNo">257</span>          k, 0, rowLen,<a name="line.257"></a>
<span class="sourceLineNo">258</span>          k, rowLen, cfLen,<a name="line.258"></a>
<span class="sourceLineNo">259</span>          k, rowLen + cfLen, k.length - rowLen - cfLen,<a name="line.259"></a>
<span class="sourceLineNo">260</span>          rand.nextLong(),<a name="line.260"></a>
<span class="sourceLineNo">261</span>          generateKeyType(rand),<a name="line.261"></a>
<span class="sourceLineNo">262</span>          v, 0, v.length);<a name="line.262"></a>
<span class="sourceLineNo">263</span>      writer.append(kv);<a name="line.263"></a>
<span class="sourceLineNo">264</span>    }<a name="line.264"></a>
<span class="sourceLineNo">265</span>  }<a name="line.265"></a>
<span class="sourceLineNo">266</span><a name="line.266"></a>
<span class="sourceLineNo">267</span>  @org.junit.Rule<a name="line.267"></a>
<span class="sourceLineNo">268</span>  public org.apache.hadoop.hbase.ResourceCheckerJUnitRule cu =<a name="line.268"></a>
<span class="sourceLineNo">269</span>    new org.apache.hadoop.hbase.ResourceCheckerJUnitRule();<a name="line.269"></a>
<span class="sourceLineNo">270</span>}<a name="line.270"></a>
<span class="sourceLineNo">271</span><a name="line.271"></a>




























































</pre>
</div>
</body>
</html>
